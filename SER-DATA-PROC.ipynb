{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "proj_dir = os.getcwd()\n",
    "label_dir = os.path.join(proj_dir, 'emotiondetection/features_labels_lld/labels')\n",
    "lld_dir = os.path.join(proj_dir, 'emotiondetection/features_labels_lld/lld')\n",
    "\n",
    "pickle_train_y_list = 'pickle_train_y_list'\n",
    "pickle_train_x_list = 'pickle_train_x_list'\n",
    "\n",
    "pickle_test_y_list = 'pickle_test_y_list'\n",
    "pickle_test_x_list = 'pickle_test_x_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y_dict:  9959\n",
      "test_y_dict:  8257\n"
     ]
    }
   ],
   "source": [
    "train_y_dict = {}\n",
    "with open(os.path.join(label_dir, 'train.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        line_list = line.split(' ')\n",
    "        train_y_dict[line_list[0]] = line_list[1]\n",
    "print 'train_y_dict: ', len(train_y_dict)\n",
    "\n",
    "test_y_dict = {}\n",
    "with open(os.path.join(label_dir, 'test.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line_list = line.strip().split(' ')\n",
    "        test_y_dict[line_list[0]] = line_list[1]\n",
    "print 'test_y_dict: ', len(test_y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_dict:  9959\n",
      "test_x_dict:  8257\n"
     ]
    }
   ],
   "source": [
    "train_x_dict = {}\n",
    "for file_name in os.listdir(os.path.join(lld_dir, 'train')):\n",
    "    with open(os.path.join(lld_dir, 'train', file_name), 'r') as f:\n",
    "        key = file_name.split('.')[0]\n",
    "        train_x_dict[key] = [float(line.strip()) for line in f.readlines()]\n",
    "print 'train_x_dict: ', len(train_x_dict)\n",
    "\n",
    "test_x_dict = {}\n",
    "for file_name in os.listdir(os.path.join(lld_dir, 'test')):\n",
    "    with open(os.path.join(lld_dir, 'test', file_name), 'r') as f:\n",
    "        key = file_name.split('.')[0]\n",
    "        test_x_dict[key] = [float(line.strip()) for line in f.readlines()]\n",
    "print 'test_x_dict: ', len(test_x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_to_int(lb):\n",
    "    return ['A', 'E', 'N', 'P', 'R'].index(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y_items = train_y_dict.items()\n",
    "train_y_list = [val[1] for val in sorted(train_y_items)]\n",
    "train_y_list = map(label_to_int, train_y_list)\n",
    "\n",
    "train_x_items = train_x_dict.items()\n",
    "train_x_list = [val[1] for val in sorted(train_x_items)]\n",
    "\n",
    "test_y_items = test_y_dict.items()\n",
    "test_y_list = [val[1] for val in sorted(test_y_items)]\n",
    "test_y_list = map(label_to_int, test_y_list)\n",
    "\n",
    "test_x_items = test_x_dict.items()\n",
    "test_x_list = [val[1] for val in sorted(test_x_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y_list = np.array(train_y_list)\n",
    "train_x_list = np.array(train_x_list)\n",
    "\n",
    "test_y_list = np.array(test_y_list)\n",
    "test_x_list = np.array(test_x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9959,) (9959, 384)\n",
      "(8257,) (8257, 384)\n"
     ]
    }
   ],
   "source": [
    "print train_y_list.shape, train_x_list.shape\n",
    "print test_y_list.shape, test_x_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_y_list, open(pickle_train_y_list, 'w'))\n",
    "pickle.dump(train_x_list, open(pickle_train_x_list, 'w'))\n",
    "\n",
    "pickle.dump(test_y_list, open(pickle_test_y_list, 'w'))\n",
    "pickle.dump(test_x_list, open(pickle_test_x_list, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_dir = os.getcwd()\n",
    "mfcc_dir = os.path.join(proj_dir, 'emotiondetection/mfcc_csv')\n",
    "\n",
    "pickle_train_mfcc_x_list = 'pickle_train_mfcc_x_list'\n",
    "\n",
    "pickle_test_mfcc_x_list = 'pickle_test_mfcc_x_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mfcc_x_dict:  9959\n",
      "test_x_dict:  8257\n"
     ]
    }
   ],
   "source": [
    "train_mfcc_x_dict = {}\n",
    "for file_name in os.listdir(os.path.join(mfcc_dir, 'train')):\n",
    "    with open(os.path.join(mfcc_dir, 'train', file_name), 'r') as f:\n",
    "        key = file_name.split('.')[0]\n",
    "        train_mfcc_x_dict[key] = np.loadtxt(f, delimiter=',')\n",
    "print 'train_mfcc_x_dict: ', len(train_mfcc_x_dict)\n",
    "\n",
    "test_mfcc_x_dict = {}\n",
    "for file_name in os.listdir(os.path.join(mfcc_dir, 'test')):\n",
    "    with open(os.path.join(mfcc_dir, 'test', file_name), 'r') as f:\n",
    "        key = file_name.split('.')[0]\n",
    "        test_mfcc_x_dict[key] = np.loadtxt(f, delimiter=',')\n",
    "print 'test_x_dict: ', len(test_mfcc_x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mfcc_x_items = train_mfcc_x_dict.items()\n",
    "train_mfcc_x_list = [val[1] for val in sorted(train_mfcc_x_items)]\n",
    "\n",
    "test_mfcc_x_items = test_mfcc_x_dict.items()\n",
    "test_mfcc_x_list = [val[1] for val in sorted(test_mfcc_x_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mfcc_x_list = np.array(train_mfcc_x_list)\n",
    "\n",
    "test_mfcc_x_list = np.array(test_mfcc_x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9959,) (9959,)\n",
      "(8257,) (8257,)\n"
     ]
    }
   ],
   "source": [
    "print train_y_list.shape, train_mfcc_x_list.shape\n",
    "print test_y_list.shape, test_mfcc_x_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_mfcc_x_list, open(pickle_train_mfcc_x_list, 'w'))\n",
    "\n",
    "pickle.dump(test_mfcc_x_list, open(pickle_test_mfcc_x_list, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 39)\n",
      "(120, 39)\n",
      "(237, 39)\n",
      "(127, 39)\n",
      "(101, 39)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print train_mfcc_x_list[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对训练数据中某些数量比较多的类做降采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slhome/cc001/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class 0 : 3\n",
      "number of class 1 : 59\n",
      "number of class 2 : 1373\n",
      "number of class 3 : 674\n",
      "number of class 4 : 2\n"
     ]
    }
   ],
   "source": [
    "train_y_list = pickle.load(open(pickle_train_y_list))\n",
    "train_x_list = pickle.load(open(pickle_train_x_list))\n",
    "\n",
    "test_y_list = pickle.load(open(pickle_test_y_list))\n",
    "test_x_list = pickle.load(open(pickle_test_x_list))\n",
    "\n",
    "# ENN down-sampling training data\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN\n",
    "enn = EditedNearestNeighbours()\n",
    "# enn = SMOTEENN()\n",
    "\n",
    "train_x_list_enn, train_y_list_enn = enn.fit_sample(train_x_list, train_y_list)\n",
    "\n",
    "# split training data to 5 different classes\n",
    "train_x_lists = [[] for i in range(5)]\n",
    "train_y_lists = [[] for i in range(5)]\n",
    "for i in xrange(len(train_y_list_enn)):\n",
    "    train_x_lists[int(train_y_list_enn[i])].append(train_x_list_enn[i])\n",
    "    train_y_lists[int(train_y_list_enn[i])].append(train_y_list_enn[i])\n",
    "for i in xrange(5):\n",
    "    print 'number of class', i, ':', len(train_x_lists[i])\n",
    "\n",
    "train_x_lists_enn = train_x_lists\n",
    "train_y_lists_enn = train_y_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class 0 : 881 881\n",
      "number of class 1 : 2093 2093\n",
      "number of class 2 : 5590 5590\n",
      "number of class 3 : 674 674\n",
      "number of class 4 : 721 721\n",
      "------------------\n",
      "number of class 0 : 881\n",
      "number of class 1 : 2093\n",
      "number of class 2 : 1373\n",
      "number of class 3 : 674\n",
      "number of class 4 : 721\n"
     ]
    }
   ],
   "source": [
    "train_y_list = pickle.load(open(pickle_train_y_list))\n",
    "train_x_list = pickle.load(open(pickle_train_x_list))\n",
    "\n",
    "test_y_list = pickle.load(open(pickle_test_y_list))\n",
    "test_x_list = pickle.load(open(pickle_test_x_list))\n",
    "\n",
    "# split training data to 5 different classes\n",
    "train_x_lists = [[] for i in range(5)]\n",
    "train_y_lists = [[] for i in range(5)]\n",
    "for i in xrange(len(train_y_list)):\n",
    "    train_x_lists[int(train_y_list[i])].append(train_x_list[i])\n",
    "    train_y_lists[int(train_y_list[i])].append(train_y_list[i])\n",
    "for i in xrange(5):\n",
    "    print 'number of class', i, ':', len(train_x_lists[i]), len(train_y_lists[i])\n",
    "print '------------------'\n",
    "\n",
    "train_x_lists[2] = train_x_lists_enn[2]\n",
    "train_y_lists[2] = train_y_lists_enn[2]\n",
    "\n",
    "train_x_list = np.vstack(train_x_lists)\n",
    "train_y_list = np.concatenate(train_y_lists)\n",
    "\n",
    "# split training data to 5 different classes\n",
    "train_x_lists = [[] for i in range(5)]\n",
    "for i in xrange(len(train_y_list)):\n",
    "    train_x_lists[int(train_y_list[i])].append(train_x_list[i])\n",
    "for i in xrange(5):\n",
    "    print 'number of class', i, ':', len(train_x_lists[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_train_x_small_list = 'pickle_train_x_small_list'\n",
    "pickle_train_y_small_list = 'pickle_train_y_small_list'\n",
    "\n",
    "pickle.dump(train_x_list, open(pickle_train_x_small_list, 'w'))\n",
    "pickle.dump(train_y_list, open(pickle_train_y_small_list, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
